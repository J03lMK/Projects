{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movement Monitoring Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial Setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install PySpark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark==2.4.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
      "\u001b[K     |████████████████████████████████| 217.8MB 34kB/s  eta 0:00:01                              | 1.3MB 2.6MB/s eta 0:01:23�                               | 5.0MB 2.6MB/s eta 0:01:22     |█▎                              | 8.6MB 2.6MB/s eta 0:01:22   |█▊                              | 11.4MB 5.5MB/s eta 0:00:38     |█▊                              | 11.7MB 5.5MB/s eta 0:00:38     |███                             | 21.0MB 5.3MB/s eta 0:00:37     |█████▌                          | 37.1MB 5.3MB/s eta 0:00:35     |█████▋                          | 37.9MB 5.3MB/s eta 0:00:3504     |███████████▏                    | 76.0MB 5.1MB/s eta 0:00:28     |███████████▎                    | 76.7MB 5.1MB/s eta 0:00:28     |███████████▌                    | 78.2MB 5.1MB/s eta 0:00:28████████████                    | 81.4MB 2.8MB/s eta 0:00:49    | 81.8MB 2.8MB/s eta 0:00:49MB/s eta 0:00:24     |██████████████▍                 | 98.2MB 5.5MB/s eta 0:00:22     |██████████████▊                 | 100.5MB 5.5MB/s eta 0:00:22�██████████████▉               | 114.7MB 5.4MB/s eta 0:00:20     |█████████████████▏              | 116.6MB 5.4MB/s eta 0:00:19     |█████████████████▏              | 117.0MB 5.4MB/s eta 0:00:19��█████████             | 129.2MB 2.6MB/s eta 0:00:34 130.0MB 2.6MB/s eta 0:00:34[K     |███████████████████▌            | 133.1MB 2.6MB/s eta 0:00:33[K     |███████████████████▉            | 135.3MB 2.6MB/s eta 0:00:32�█████████▏          | 144.1MB 2.7MB/s eta 0:00:28��█████████████████████▏         | 151.0MB 5.4MB/s eta 0:00:135MB 5.3MB/s eta 0:00:12     |███████████████████████▊        | 161.2MB 5.5MB/s eta 0:00:11     |███████████████████████▉        | 162.2MB 5.5MB/s eta 0:00:11     |███████████████████████▉        | 162.5MB 5.5MB/s eta 0:00:11��██████████████████      | 177.3MB 4.8MB/s eta 0:00:09:09     |██████████████████████████▍     | 179.8MB 5.5MB/s eta 0:00:07     |███████████████████████████     | 183.6MB 5.5MB/s eta 0:00:07   | 185.9MB 5.3MB/s eta 0:00:076     |███████████████████████████▊    | 188.9MB 5.3MB/s eta 0:00:06   | 189.4MB 5.3MB/s eta 0:00:06��█████████▎   | 192.3MB 5.3MB/s eta 0:00:05��█████████▋   | 194.9MB 5.3MB/s eta 0:00:05��█████████████████████  | 204.6MB 5.2MB/s eta 0:00:03B 1.8MB/s eta 0:00:026.2MB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py4j==0.10.7 (from pyspark==2.4.5)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 5.4MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
     ]
    }
   ],
   "source": [
    "# Install PySpark Python package \n",
    "!pip install pyspark==2.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "# SparkContext: Main entry point for Spark functionality\n",
    "# SparkConf: For configuring Spark\n",
    "# SparkSession: Allows programming Spark with DataFrame and Dataset APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkContext object\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "# getOrCreate(): get a new entity or an existing entity from the database, if such entity exists\n",
    "# setMaster: Set master URL to connect to, if local set as above\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe \n",
    "df = spark.read.parquet('accelerometer.parquet')\n",
    "# register a corresponding query table \n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the unfiltered datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------------------+-----------+\n",
      "|  x|  y|  z|              source|      class|\n",
      "+---+---+---+--------------------+-----------+\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 21| 52| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 51| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 20| 50| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 52| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 50| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 51| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 21| 51| 33|Accelerometer-201...|Brush_teeth|\n",
      "| 20| 50| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|\n",
      "| 20| 51| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 18| 49| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 19| 48| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 16| 53| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 18| 52| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 18| 51| 32|Accelerometer-201...|Brush_teeth|\n",
      "+---+---+---+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- x: integer (nullable = true)\n",
      " |-- y: integer (nullable = true)\n",
      " |-- z: integer (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display top 20 rows and the df scema\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pipeline Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the ML packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, Normalizer, MinMaxScaler\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the processing objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the movement classes from strings to indexes, and one-hot encode them\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"classIndex\")\n",
    "encoder = OneHotEncoder(inputCol=\"classIndex\", outputCol=\"catVec\")\n",
    "\n",
    "# combine the coordinates into vectors \n",
    "vectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"], outputCol=\"features\")\n",
    "\n",
    "# normalize the vector coordinates from 0 to 1 and standardize the scale\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n",
    "minmaxscaler = MinMaxScaler(inputCol=\"features_norm\", outputCol=\"scaled_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# pipeline uses all the tranform object above\n",
    "pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, minmaxscaler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets process the dataset by fitting it into the pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+\n",
      "|  x|  y|  z|              source|      class|classIndex|        catVec|        features|       features_norm|     scaled_features|\n",
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|[0.26684636118598...|\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|[0.26684636118598...|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|[0.25950196592398...|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|[0.25950196592398...|\n",
      "| 21| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,52.0,34.0]|[0.19626168224299...|[0.25233644859813...|\n",
      "| 22| 51| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,34.0]|[0.20560747663551...|[0.26435246995994...|\n",
      "| 20| 50| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,35.0]|[0.19047619047619...|[0.24489795918367...|\n",
      "| 22| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,34.0]|[0.20370370370370...|[0.26190476190476...|\n",
      "| 22| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,50.0,34.0]|[0.20754716981132...|[0.26684636118598...|\n",
      "| 22| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,35.0]|[0.20370370370370...|[0.26190476190476...|\n",
      "| 21| 51| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,51.0,33.0]|[0.2,0.4857142857...|[0.25714285714285...|\n",
      "| 20| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,34.0]|[0.19230769230769...|[0.24725274725274...|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|[0.26213592233009...|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|[0.26213592233009...|\n",
      "| 20| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,51.0,35.0]|[0.18867924528301...|[0.24258760107816...|\n",
      "| 18| 49| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,49.0,34.0]|[0.17821782178217...|[0.22913719943422...|\n",
      "| 19| 48| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[19.0,48.0,34.0]|[0.18811881188118...|[0.24186704384724...|\n",
      "| 16| 53| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[16.0,53.0,34.0]|[0.15533980582524...|[0.19972260748959...|\n",
      "| 18| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,52.0,35.0]|[0.17142857142857...|[0.22040816326530...|\n",
      "| 18| 51| 32|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,51.0,32.0]|[0.17821782178217...|[0.22913719943422...|\n",
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform the df and remove the original columns\n",
    "processed_df = pipeline.fit(df).transform(df)\n",
    "\n",
    "processed_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predictive Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML algorithms are suitable for the objective - https://spark.apache.org/docs/latest/ml-clustering.html#gaussian-mixture-model-gmm\n",
    "\n",
    "#### a. Clustering - K-Means and GMM (also returns the probabilty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.clustering import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a K-Means/GMM object with K= # of movement types in the dataset\n",
    "kmeans = KMeans(featuresCol=\"features\").setK(14).setSeed(1)\n",
    "gmm = GaussianMixture(featuresCol=\"features\").setK(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the objects in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+----------+\n",
      "|  x|  y|  z|              source|      class|classIndex|        catVec|        features|       features_norm|     scaled_features|prediction|\n",
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+----------+\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|[0.26684636118598...|        11|\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|[0.26684636118598...|        11|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|[0.25950196592398...|        11|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|[0.25950196592398...|        11|\n",
      "| 21| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,52.0,34.0]|[0.19626168224299...|[0.25233644859813...|        11|\n",
      "| 22| 51| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,34.0]|[0.20560747663551...|[0.26435246995994...|        11|\n",
      "| 20| 50| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,35.0]|[0.19047619047619...|[0.24489795918367...|        11|\n",
      "| 22| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,34.0]|[0.20370370370370...|[0.26190476190476...|        11|\n",
      "| 22| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,50.0,34.0]|[0.20754716981132...|[0.26684636118598...|        11|\n",
      "| 22| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,35.0]|[0.20370370370370...|[0.26190476190476...|        11|\n",
      "| 21| 51| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,51.0,33.0]|[0.2,0.4857142857...|[0.25714285714285...|        11|\n",
      "| 20| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,34.0]|[0.19230769230769...|[0.24725274725274...|        11|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|[0.26213592233009...|        11|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|[0.26213592233009...|        11|\n",
      "| 20| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,51.0,35.0]|[0.18867924528301...|[0.24258760107816...|        11|\n",
      "| 18| 49| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,49.0,34.0]|[0.17821782178217...|[0.22913719943422...|         8|\n",
      "| 19| 48| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[19.0,48.0,34.0]|[0.18811881188118...|[0.24186704384724...|         8|\n",
      "| 16| 53| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[16.0,53.0,34.0]|[0.15533980582524...|[0.19972260748959...|         8|\n",
      "| 18| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,52.0,35.0]|[0.17142857142857...|[0.22040816326530...|         8|\n",
      "| 18| 51| 32|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,51.0,32.0]|[0.17821782178217...|[0.22913719943422...|         8|\n",
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+----------+--------------------+\n",
      "|  x|  y|  z|              source|      class|classIndex|        catVec|        features|       features_norm|     scaled_features|prediction|         probability|\n",
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+----------+--------------------+\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|[0.26684636118598...|        11|[8.52921163136684...|\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|[0.26684636118598...|        11|[8.52921163136684...|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|[0.25950196592398...|        11|[1.21899204637739...|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|[0.25950196592398...|        11|[1.21899204637739...|\n",
      "| 21| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,52.0,34.0]|[0.19626168224299...|[0.25233644859813...|        11|[1.33127715026109...|\n",
      "| 22| 51| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,34.0]|[0.20560747663551...|[0.26435246995994...|        11|[1.02073007487147...|\n",
      "| 20| 50| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,35.0]|[0.19047619047619...|[0.24489795918367...|        11|[9.86094332009228...|\n",
      "| 22| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,34.0]|[0.20370370370370...|[0.26190476190476...|        11|[1.20792117118796...|\n",
      "| 22| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,50.0,34.0]|[0.20754716981132...|[0.26684636118598...|        11|[9.38165966211533...|\n",
      "| 22| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,35.0]|[0.20370370370370...|[0.26190476190476...|        11|[9.96415921326547...|\n",
      "| 21| 51| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,51.0,33.0]|[0.2,0.4857142857...|[0.25714285714285...|        11|[1.14678801753024...|\n",
      "| 20| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,34.0]|[0.19230769230769...|[0.24725274725274...|        11|[1.01982911339452...|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|[0.26213592233009...|        11|[1.05606447564632...|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|[0.26213592233009...|        11|[1.05606447564632...|\n",
      "| 20| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,51.0,35.0]|[0.18867924528301...|[0.24258760107816...|        11|[1.17792513406238...|\n",
      "| 18| 49| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,49.0,34.0]|[0.17821782178217...|[0.22913719943422...|        11|[3.82282004992733...|\n",
      "| 19| 48| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[19.0,48.0,34.0]|[0.18811881188118...|[0.24186704384724...|        11|[6.76407108523401...|\n",
      "| 16| 53| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[16.0,53.0,34.0]|[0.15533980582524...|[0.19972260748959...|        11|[5.71715949080716...|\n",
      "| 18| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,52.0,35.0]|[0.17142857142857...|[0.22040816326530...|        11|[2.30579338529981...|\n",
      "| 18| 51| 32|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,51.0,32.0]|[0.17821782178217...|[0.22913719943422...|        11|[2.42236003601330...|\n",
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pipeline uses all the tranform object above\n",
    "pipeline_kmeans = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, minmaxscaler, kmeans])\n",
    "pipeline_gmm = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, minmaxscaler, gmm])\n",
    "\n",
    "# transform the df and remove the original columns\n",
    "model_kmeans = pipeline_kmeans.fit(df)\n",
    "model_gmm =  pipeline_gmm.fit(df)\n",
    "pred_kmeans = model_kmeans.transform(df)\n",
    "pred_gmm = model_gmm.transform(df)\n",
    "\n",
    "pred_kmeans.show()\n",
    "pred_gmm.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracy of the models with Silhouette scores (closest to 1 is the most defined/accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "evaluator = ClusteringEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.41244594513295846\n",
      "Silhouette with squared euclidean distance = 0.1323356399641611\n"
     ]
    }
   ],
   "source": [
    "silhouette_kmeans = evaluator.evaluate(pred_kmeans)\n",
    "silhouette_gmm = evaluator.evaluate(pred_gmm)\n",
    "\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette_kmeans))\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette_gmm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Classification - Logistics Regression and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into train and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.randomSplit([0.8, 0.2])\n",
    "df_train = splits[0]\n",
    "df_test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Pipeline Processing Objects\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"], outputCol=\"features\")\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "pipeline_lr = Pipeline(stages=[indexer, vectorAssembler, normalizer,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------------------+-------------+-----+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|  x|  y|  z|              source|        class|label|       features|       features_norm|       rawPrediction|         probability|prediction|\n",
      "+---+---+---+--------------------+-------------+-----+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0| 16| 31|Accelerometer-201...|    Getup_bed|  1.0|[0.0,16.0,31.0]|[0.0,0.3404255319...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 25| 40|Accelerometer-201...|  Brush_teeth|  6.0|[0.0,25.0,40.0]|[0.0,0.3846153846...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 29| 17|Accelerometer-201...|    Getup_bed|  1.0|[0.0,29.0,17.0]|[0.0,0.6304347826...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 29| 34|Accelerometer-201...|         Walk|  0.0|[0.0,29.0,34.0]|[0.0,0.4603174603...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 29| 38|Accelerometer-201...|  Brush_teeth|  6.0|[0.0,29.0,38.0]|[0.0,0.4328358208...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 30| 24|Accelerometer-201...|Standup_chair|  7.0|[0.0,30.0,24.0]|[0.0,0.5555555555...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 30| 33|Accelerometer-201...|  Brush_teeth|  6.0|[0.0,30.0,33.0]|[0.0,0.4761904761...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 30| 34|Accelerometer-201...|    Getup_bed|  1.0|[0.0,30.0,34.0]|[0.0,0.46875,0.53...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 30| 38|Accelerometer-201...| Climb_stairs|  4.0|[0.0,30.0,38.0]|[0.0,0.4411764705...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 31| 17|Accelerometer-201...|Standup_chair|  7.0|[0.0,31.0,17.0]|[0.0,0.6458333333...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 31| 29|Accelerometer-201...|         Walk|  0.0|[0.0,31.0,29.0]|[0.0,0.5166666666...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 31| 30|Accelerometer-201...|Standup_chair|  7.0|[0.0,31.0,30.0]|[0.0,0.5081967213...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 31| 32|Accelerometer-201...|Standup_chair|  7.0|[0.0,31.0,32.0]|[0.0,0.4920634920...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 32| 23|Accelerometer-201...|    Getup_bed|  1.0|[0.0,32.0,23.0]|[0.0,0.5818181818...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 32| 32|Accelerometer-201...| Climb_stairs|  4.0|[0.0,32.0,32.0]|       [0.0,0.5,0.5]|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 32| 33|Accelerometer-201...|  Brush_teeth|  6.0|[0.0,32.0,33.0]|[0.0,0.4923076923...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 32| 33|Accelerometer-201...|Standup_chair|  7.0|[0.0,32.0,33.0]|[0.0,0.4923076923...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 32| 42|Accelerometer-201...|  Brush_teeth|  6.0|[0.0,32.0,42.0]|[0.0,0.4324324324...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 33| 32|Accelerometer-201...| Climb_stairs|  4.0|[0.0,33.0,32.0]|[0.0,0.5076923076...|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "|  0| 33| 33|Accelerometer-201...| Climb_stairs|  4.0|[0.0,33.0,33.0]|       [0.0,0.5,0.5]|[1.25605454984587...|[0.20672602283027...|       0.0|\n",
      "+---+---+---+--------------------+-------------+-----+---------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lr = pipeline_lr.fit(df_train)\n",
    "pred_lr = model_lr.transform(df_test)\n",
    "\n",
    "pred_lr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check accuracy of LR prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20610695595534892"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "eval = MulticlassClassificationEvaluator().setMetricName('accuracy').setLabelCol('label').setPredictionCol('prediction')\n",
    "eval.evaluate(pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Pipeline Processing Objects\n",
    "labelIndexer = StringIndexer(inputCol=\"class\", outputCol=\"indexedLabel\")\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"], outputCol=\"features\")\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=20)\n",
    "pipeline_rf = Pipeline(stages=[labelIndexer,vectorAssembler, featureIndexer, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------------------+-------------+------------+---------------+---------------+--------------------+--------------------+----------+\n",
      "|  x|  y|  z|              source|        class|indexedLabel|       features|indexedFeatures|       rawPrediction|         probability|prediction|\n",
      "+---+---+---+--------------------+-------------+------------+---------------+---------------+--------------------+--------------------+----------+\n",
      "|  0| 16| 31|Accelerometer-201...|    Getup_bed|         1.0|[0.0,16.0,31.0]|[0.0,16.0,31.0]|[7.29276286764421...|[0.36463814338221...|       0.0|\n",
      "|  0| 25| 40|Accelerometer-201...|  Brush_teeth|         6.0|[0.0,25.0,40.0]|[0.0,25.0,40.0]|[4.92198623961629...|[0.24609931198081...|       1.0|\n",
      "|  0| 29| 17|Accelerometer-201...|    Getup_bed|         1.0|[0.0,29.0,17.0]|[0.0,29.0,17.0]|[7.21487333949433...|[0.36074366697471...|       0.0|\n",
      "|  0| 29| 34|Accelerometer-201...|         Walk|         0.0|[0.0,29.0,34.0]|[0.0,29.0,34.0]|[8.11502316287000...|[0.4057511581435,...|       0.0|\n",
      "|  0| 29| 38|Accelerometer-201...|  Brush_teeth|         6.0|[0.0,29.0,38.0]|[0.0,29.0,38.0]|[8.06659318275703...|[0.40332965913785...|       0.0|\n",
      "|  0| 30| 24|Accelerometer-201...|Standup_chair|         7.0|[0.0,30.0,24.0]|[0.0,30.0,24.0]|[7.48817555062960...|[0.37440877753148...|       0.0|\n",
      "|  0| 30| 33|Accelerometer-201...|  Brush_teeth|         6.0|[0.0,30.0,33.0]|[0.0,30.0,33.0]|[8.77736034759589...|[0.43886801737979...|       0.0|\n",
      "|  0| 30| 34|Accelerometer-201...|    Getup_bed|         1.0|[0.0,30.0,34.0]|[0.0,30.0,34.0]|[8.77736034759589...|[0.43886801737979...|       0.0|\n",
      "|  0| 30| 38|Accelerometer-201...| Climb_stairs|         4.0|[0.0,30.0,38.0]|[0.0,30.0,38.0]|[8.06659318275703...|[0.40332965913785...|       0.0|\n",
      "|  0| 31| 17|Accelerometer-201...|Standup_chair|         7.0|[0.0,31.0,17.0]|[0.0,31.0,17.0]|[7.48817555062960...|[0.37440877753148...|       0.0|\n",
      "|  0| 31| 29|Accelerometer-201...|         Walk|         0.0|[0.0,31.0,29.0]|[0.0,31.0,29.0]|[7.48817555062960...|[0.37440877753148...|       0.0|\n",
      "|  0| 31| 30|Accelerometer-201...|Standup_chair|         7.0|[0.0,31.0,30.0]|[0.0,31.0,30.0]|[7.95510005237011...|[0.39775500261850...|       0.0|\n",
      "|  0| 31| 32|Accelerometer-201...|Standup_chair|         7.0|[0.0,31.0,32.0]|[0.0,31.0,32.0]|[8.77736034759589...|[0.43886801737979...|       0.0|\n",
      "|  0| 32| 23|Accelerometer-201...|    Getup_bed|         1.0|[0.0,32.0,23.0]|[0.0,32.0,23.0]|[9.75809174533530...|[0.48790458726676...|       0.0|\n",
      "|  0| 32| 32|Accelerometer-201...| Climb_stairs|         4.0|[0.0,32.0,32.0]|[0.0,32.0,32.0]|[10.5803520405610...|[0.52901760202805...|       0.0|\n",
      "|  0| 32| 33|Accelerometer-201...|  Brush_teeth|         6.0|[0.0,32.0,33.0]|[0.0,32.0,33.0]|[10.5803520405610...|[0.52901760202805...|       0.0|\n",
      "|  0| 32| 33|Accelerometer-201...|Standup_chair|         7.0|[0.0,32.0,33.0]|[0.0,32.0,33.0]|[10.5803520405610...|[0.52901760202805...|       0.0|\n",
      "|  0| 32| 42|Accelerometer-201...|  Brush_teeth|         6.0|[0.0,32.0,42.0]|[0.0,32.0,42.0]|[4.48068375126739...|[0.22403418756336...|       1.0|\n",
      "|  0| 33| 32|Accelerometer-201...| Climb_stairs|         4.0|[0.0,33.0,32.0]|[0.0,33.0,32.0]|[10.5803520405610...|[0.52901760202805...|       0.0|\n",
      "|  0| 33| 33|Accelerometer-201...| Climb_stairs|         4.0|[0.0,33.0,33.0]|[0.0,33.0,33.0]|[10.5803520405610...|[0.52901760202805...|       0.0|\n",
      "+---+---+---+--------------------+-------------+------------+---------------+---------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rf = pipeline_rf.fit(df_train)\n",
    "pred_rf = model_rf.transform(df_test)\n",
    "\n",
    "pred_rf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for accuracy of RF prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44028928868225414\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(pred_rf)\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
